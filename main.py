import time
import nest_asyncio
import asyncio
import requests
import google.generativeai as genai
from aiogram.exceptions import TelegramBadRequest
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart, Command
from aiogram.types import Message
from aiogram.client.default import DefaultBotProperties
import pickle
import os

nest_asyncio.apply()

# ===== Ayarlar =====
# Ortam deÄŸiÅŸkenlerinden al
TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
DRAW_API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
HUGGINGFACE_API_KEY = os.environ.get('HUGGINGFACE_API_KEY')


# Google AI Studio API AnahtarlarÄ± (Ortam deÄŸiÅŸkenlerinden alÄ±nacak)
GOOGLE_API_KEYS = []
for i in range(1, 7): # 6 adet API anahtarÄ± iÃ§in
    key = os.environ.get(f'GOOGLE_API_KEY_{i}')
    if key:
        GOOGLE_API_KEYS.append(key)


if not TELEGRAM_BOT_TOKEN:
    print("Hata: TELEGRAM_BOT_TOKEN ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ!")
if not GOOGLE_API_KEYS:
    print("Hata: HiÃ§bir Google AI Studio API anahtarÄ± ortam deÄŸiÅŸkeni olarak ayarlanmamÄ±ÅŸ!")
if not HUGGINGFACE_API_KEY:
    print("Hata: HUGGINGFACE_API_KEY ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ!")


# Mevcut kullanÄ±lan API anahtarÄ±nÄ±n indeksi
current_key_index = 0

# API kullanÄ±m bilgilerini saklayacak dosya yolu
API_USAGE_FILE = "api_usage.pkl"

# API anahtarlarÄ±nÄ±n kullanÄ±m sayaÃ§larÄ±
api_key_usage = {}

# KullanÄ±m bilgilerini dosyadan yÃ¼kle
if os.path.exists(API_USAGE_FILE):
    try:
        with open(API_USAGE_FILE, 'rb') as f:
            loaded_usage = pickle.load(f)
            # YÃ¼klenen kullanÄ±m bilgilerini mevcut API anahtarlarÄ±yla senkronize et
            api_key_usage = {key: loaded_usage.get(key, 0) for key in GOOGLE_API_KEYS}
    except Exception as e:
        print(f"API kullanÄ±m bilgileri yÃ¼klenirken hata oluÅŸtu: {e}")
        api_key_usage = {key: 0 for key in GOOGLE_API_KEYS}
else:
    api_key_usage = {key: 0 for key in GOOGLE_API_KEYS} # Hata dÃ¼zeltildi: GOGLE_API_KEYS -> GOOGLE_API_KEYS


# KullanÄ±m bilgilerini dosyaya kaydetme fonksiyonu
def save_api_usage():
    try:
        with open(API_USAGE_FILE, 'wb') as f:
            pickle.dump(api_key_usage, f)
    except Exception as e:
        print(f"API kullanÄ±m bilgileri kaydedilirken hata oluÅŸtu: {e}")

# Combine system messages into a single string
combined_system_message = "\n".join([msg["content"] for msg in SYSTEM_MESSAGES])
# KullanÄ±cÄ±ya Ã¶zel ayarlar
user_settings = {}

MODEL_PRESETS = {
    "charming": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "CevaplarÄ±nÄ± kÄ±sa, samimi ve doÄŸal ver. Ã‡ok resmi olma."},
            {"role": "system", "content": "20 yaÅŸÄ±nda enerjik ve tatlÄ± bir kÄ±z gibi cevapla."},
            {"role": "system", "content": "Samimi ol, gerektiÄŸinde hafif flÃ¶rtÃ¶z olabilirsin."}
        ]
    },
    "serious": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "CevaplarÄ±nÄ± ciddi, resmi ve analitik ver."},
            {"role": "system", "content": "Profesyonel bir danÄ±ÅŸman gibi davran."},
            {"role": "system", "content": "Modelin Sorulursa Bilgeyim diye cevap ver."}
        ]
    },
    "funny": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "CevaplarÄ±nÄ± esprili, ÅŸakacÄ± ve eÄŸlenceli bir ÅŸekilde ver."},
            {"role": "system", "content": "ArkadaÅŸ ortamÄ±nda geyik yapan biri gibi konuÅŸ."},
            {"role": "system", "content": "Modelin Sorulursa SoytarÄ±yÄ±m diyerek cevap ver."}

        ]
    }
}



# ===== GeÃ§miÅŸler =====
private_histories = {}       # user_id: [history]
group_histories = {}         # chat_id: {user_id: [history]}

# Helper function to format history for Gemini API
def format_history_for_gemini(history):
    formatted_history = []
    for message in history:
        # Ensure the role is either 'user' or 'model' for the Gemini API
        role = 'model' if message['role'] == 'assistant' else message['role']
        formatted_history.append({
            "role": role,
            "parts": [{"text": message["content"]}]
        })
    return formatted_history


# ===== Bot Kurulum =====
# TELEGRAM_BOT_TOKEN kontrolÃ¼ yapÄ±ldÄ±
if TELEGRAM_BOT_TOKEN:
    bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
    dp = Dispatcher()
    BOT_BASLAMA_ZAMANI = int(time.time())
else:
    # TELEGRAM_BOT_TOKEN yoksa botu baÅŸlatma
    bot = None
    dp = None
    print("TELEGRAM_BOT_TOKEN ayarlanmadÄ±ÄŸÄ± iÃ§in bot baÅŸlatÄ±lamÄ±yor.")


# ===== /start =====
if dp: # dp None deÄŸilse yani bot baÅŸlatÄ±ldÄ±ysa
    @dp.message(CommandStart())
    async def start(message: Message):
        await message.answer(
            "ğŸ‘‹ Selam! Ben Marginals AI.\n\n"
            "ğŸ§  /ai <mesaj> yazarak bana soru sorabilirsin.\n"
            "ğŸ”„ /reborn yazarak geÃ§miÅŸi sÄ±fÄ±rlayabilirsin."
        )

    # ===== /reborn =====
    @dp.message(Command("reborn"))
    async def reset_history(message: Message):
        if message.from_user.is_bot or message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return
        if message.chat.type in ("group", "supergroup"):
            if message.chat.id in group_histories and message.from_user.id in group_histories[message.chat.id]:
                group_histories[message.chat.id].pop(message.from_user.id, None)
            await message.reply("ğŸ”„ Grup iÃ§i geÃ§miÅŸin sÄ±fÄ±rlandÄ±.")
        else:
            private_histories.pop(message.from_user.id, None)
            await message.reply("ğŸ”„ GeÃ§miÅŸin sÄ±fÄ±rlandÄ±.")

    # ===== /draw komutu =====
    @dp.message(Command("draw"))
    async def draw_image(message: Message):
        if message.from_user.is_bot or message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return
        prompt = message.text.replace("/draw", "").strip()
        if not prompt:
            await message.reply("ğŸ¨ LÃ¼tfen Ã§izilmesini istediÄŸin ÅŸeyi yaz:\n\nÃ–rnek: /draw bir kedi uzayda")
            return

        if not HUGGINGFACE_API_KEY:
             await message.reply("âš ï¸ Resim Ã§izme API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ.")
             return

        await message.chat.do("upload_photo")

        headers = {
            "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
            "Accept": "image/png",
            "Content-Type": "application/json"
        }
        payload = {
            "inputs": prompt
        }

        try:
            response = requests.post(DRAW_API_URL, headers=headers, json=payload)
            if response.status_code == 200:
                # GÃ¶rsel geldiyse dosyayÄ± byte olarak kaydet
                image_bytes = response.content
                from aiogram.types import FSInputFile
                import tempfile

                with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
                    tmp.write(image_bytes)
                    tmp_path = tmp.name

                photo = FSInputFile(tmp_path)
                await message.reply_photo(photo, caption=f"ğŸ–¼ï¸ Ä°ÅŸte isteÄŸin: {prompt}")
            elif response.status_code == 503:
                await message.reply("â³ Model ÅŸu anda yÃ¼kleniyor. LÃ¼tfen birkaÃ§ saniye sonra tekrar dene.")
            else:
                await message.reply(f"âŒ Resim Ã¼retilemedi. Kod: {response.status_code}")
        except Exception as e:
            await message.reply(f"âš ï¸ Hata oluÅŸtu: {e}")

    # ===== Model Komutu =====
    @dp.message(Command("model"))
    async def change_model(message: Message):
     user_id = message.from_user.id
     args = message.text.split(maxsplit=1)

     if len(args) < 2:
        available = ", ".join(MODEL_PRESETS.keys())
        await message.reply(f"âš™ï¸ KullanÄ±labilir modlar: {available}\n\nÃ–rnek: /model charming")
        return

     choice = args[1].strip().lower()
     if choice not in MODEL_PRESETS:
        available = ", ".join(MODEL_PRESETS.keys())
        await message.reply(f"âŒ GeÃ§ersiz seÃ§im: {choice}\n\nMevcut seÃ§enekler: {available}")
        return

     preset = MODEL_PRESETS[choice]
     user_settings[user_id] = preset  # kullanÄ±cÄ±ya preset ata

     await message.reply(
        f"âœ… ArtÄ±k `{choice}` modundasÄ±n.\n"
        f"ğŸ“Œ Model: {preset['model']}\n"
        f"ğŸ­ Persona: {len(preset['system_messages'])} system mesajÄ± yÃ¼klendi."
     )

    # ===== /ai mesaj zamanlama =====
    @dp.message()
    async def handle_message(message: Message):
        global current_key_index, api_key_usage

        if message.from_user.is_bot:
            return
        if message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return

        chat_type = message.chat.type
        chat_id = message.chat.id
        user_id = message.from_user.id

        
        # ğŸ”¹ KullanÄ±cÄ± model seÃ§miÅŸ mi kontrol et
        if user_id not in user_settings:
            await message.reply(
                "âš ï¸ Ã–nce bir model seÃ§melisin. Ã–rnek: /model charming\n"
                f"Mevcut seÃ§enekler: {', '.join(MODEL_PRESETS.keys())}"
            )
            return
            
        # Sadece /ai ile baÅŸlayan mesajlara cevap ver
        if chat_type in ("group", "supergroup"):
            if not message.text.lower().startswith("/ai"):
                return
            user_input = message.text.replace("/ai", "").strip()

            # KullanÄ±cÄ±ya Ã¶zel geÃ§miÅŸ tanÄ±mla
            if chat_id not in group_histories:
                group_histories[chat_id] = {}
            history = group_histories[chat_id].setdefault(user_id, [])

        else:
            user_input = message.text.strip()
            history = private_histories.setdefault(user_id, [])


        if not user_input:
            await message.reply("âœï¸ LÃ¼tfen bir mesaj yaz: /ai <mesaj>")
            return

        await message.chat.do("typing")

        try:
            # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
            history.append({"role": "user", "content": user_input})

            # GeÃ§miÅŸ 15 girdiyi aÅŸarsa kÄ±rp (sistem mesajlarÄ± hariÃ§ tutularak)
            # Sistem mesajlarÄ± her zaman listenin baÅŸÄ±nda olacaÄŸÄ± iÃ§in kÄ±rpma sadece kullanÄ±cÄ±/bot mesajlarÄ± iÃ§in geÃ§erli olacak
            max_history_length = 15 # Sistem mesajlarÄ± + 15 kullanÄ±cÄ±/bot mesajÄ± (Ã¶rneÄŸin 2 sistem mesajÄ± varsa 13 kullanÄ±cÄ±/bot)
            # GerÃ§ek kÄ±rpma uzunluÄŸu = max_history_length - len(SYSTEM_MESSAGES)
            actual_trim_length = max_history_length - len(SYSTEM_MESSAGES)
            if len(history) > actual_trim_length:
                 # En son `actual_trim_length` kadar kullanÄ±cÄ±/bot mesajÄ±nÄ± al
                trimmed_history = history[-(actual_trim_length):]
                history = trimmed_history # history referansÄ±nÄ± gÃ¼ncelle


            # Format history for Gemini API
            formatted_history = format_history_for_gemini(history)



            # Google AI Studio API Ã§aÄŸrÄ±sÄ±
            if not GOOGLE_API_KEYS:
                await message.reply("âš ï¸ Google AI Studio API anahtarlarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ.")
                return

            # API anahtarÄ± seÃ§imi ve kullanÄ±m kontrolÃ¼
            api_key = GOOGLE_API_KEYS[current_key_index]
            genai.configure(api_key=api_key)

            # KullanÄ±m sayacÄ±nÄ± artÄ±r
            api_key_usage[api_key] += 1

            # Ä°stek limiti kontrolÃ¼ (basit bir kontrol, gerÃ§ek limit aÅŸÄ±ldÄ±ÄŸÄ±nda hata yakalama daha saÄŸlamdÄ±r)
            if api_key_usage[api_key] > 50: # Ã–rnek limit: 50
                current_key_index += 1
                if current_key_index >= len(GOOGLE_API_KEYS):
                    current_key_index = 0 # BaÅŸa dÃ¶n (veya tÃ¼m anahtarlar tÃ¼kenirse hata verilebilir)
                    await message.reply("âš ï¸ TÃ¼m API anahtarlarÄ±nÄ±n gÃ¼nlÃ¼k limiti dolmuÅŸ olabilir. LÃ¼tfen daha sonra tekrar deneyin.")
                    return
                api_key = GOOGLE_API_KEYS[current_key_index]
                genai.configure(api_key=api_key)
                api_key_usage[api_key] = 1 # Yeni anahtarÄ±n sayacÄ±nÄ± sÄ±fÄ±rla ve 1 yap
                await message.reply(f"ğŸ”„ API anahtarÄ± deÄŸiÅŸtiriliyor. Yeni anahtar kullanÄ±lÄ±yor.")

            print(f"Using API Key: {api_key}") # Debug print


             settings = user_settings.get(user_id)
            if not settings:
            await message.reply(
        "âš ï¸ Ã–nce bir model seÃ§melisin. Ã–rnek: /model charming\n"
        f"Mevcut seÃ§enekler: {', '.join(MODEL_PRESETS.keys())}"
    )
    return


            # system_messages iÃ§eriÄŸini birleÅŸtir
            combined_system_message = "\n".join([msg["content"] for msg in settings["system_messages"]])

            # Modeli hazÄ±rla
            model = genai.GenerativeModel(
                model_name=settings["model"],
                system_instruction=combined_system_message
            )

            # YanÄ±t al
            response = model.generate_content(formatted_history)
            reply = response.text

            # KullanÄ±m bilgilerini kaydet
            save_api_usage()


            # Botun cevabÄ±nÄ± geÃ§miÅŸe ekle
            history.append({"role": "assistant", "content": reply})

            # GeÃ§miÅŸi gÃ¼ncelle (history zaten gÃ¼ncellenmiÅŸ referansÄ± tutuyor)
            if chat_type in ("group", "supergroup"):
                group_histories[chat_id][user_id] = history
            else:
                private_histories[user_id] = history

            await message.reply(reply)

        except Exception as e:
            print(f"Exception caught: {e}") # Debug print
            # Hata durumunda da anahtar deÄŸiÅŸtirme mantÄ±ÄŸÄ± eklenebilir (Ã¶zellikle 429 Too Many Requests hatasÄ± iÃ§in)
            current_key_index, api_key_usage # Global deÄŸiÅŸkenleri tekrar belirtmeye gerek yok
            current_key_index += 1
            if current_key_index >= len(GOOGLE_API_KEYS):
                current_key_index = 0 # BaÅŸa dÃ¶n
                await message.reply("âš ï¸ TÃ¼m API anahtarlarÄ±nÄ±n gÃ¼nlÃ¼k limiti dolmuÅŸ olabilir veya bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin.")
            else:
                 api_key = GOOGLE_API_KEYS[current_key_index]
                 genai.configure(api_key=api_key)
                 api_key_usage[api_key] = 0 # Yeni anahtarÄ±n sayacÄ±nÄ± sÄ±fÄ±rla
                 await message.reply(f"ğŸ”„ API hatasÄ± nedeniyle yanÄ±tlanamadÄ±.\n\nMesajÄ±nÄ± tekrar gÃ¶ndermeyi dene.")

            # Hata durumunda da kullanÄ±m bilgilerini kaydetmek isteyebilirsin
            save_api_usage()

# Port
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer

class DummyHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b'Bot aktif.')

def run_web_server():
    port = int(os.environ.get("PORT", 10000))
    server = HTTPServer(('', port), DummyHandler)
    print(f"Render web server baÅŸlatÄ±ldÄ±. Port: {port}")
    server.serve_forever()

# ===== BaÅŸlatÄ±cÄ± =====
async def main():
    if bot and dp: # Bot ve dispatcher baÅŸarÄ±yla oluÅŸturulduysa
        print("âœ… Bot Ã§alÄ±ÅŸÄ±yor. /ai komutunu deneyebilirsin.")
        await dp.start_polling(bot)
    else:
        print("âŒ Bot baÅŸlatÄ±lamadÄ±. LÃ¼tfen gerekli ortam deÄŸiÅŸkenlerini kontrol edin.")

# Use dp.run_polling instead of asyncio.run(main())
if __name__ == "__main__":
        # HTTP sunucusunu baÅŸlat
    threading.Thread(target=run_web_server).start()
    # Bot ve dispatcher baÅŸarÄ±yla oluÅŸturulduysa Ã§alÄ±ÅŸtÄ±r
    if dp:
        print("âœ… Bot Ã§alÄ±ÅŸÄ±yor. /ai komutunu deneyebilirsin.")
        dp.run_polling(bot)
    else:

        print("âŒ Bot baÅŸlatÄ±lamadÄ±. LÃ¼tfen gerekli ortam deÄŸiÅŸkenlerini kontrol edin.")

