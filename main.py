import time
import nest_asyncio
import asyncio
import requests
import google.generativeai as genai
from aiogram.exceptions import TelegramBadRequest
from aiogram import Bot, Dispatcher
from aiogram.enums import ParseMode
from aiogram.filters import CommandStart, Command
from aiogram.types import Message
from aiogram.client.default import DefaultBotProperties
import pickle
import os

nest_asyncio.apply()

# ===== Ayarlar =====
TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
DRAW_API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
HUGGINGFACE_API_KEY = os.environ.get('HUGGINGFACE_API_KEY')


# Google AI Studio API AnahtarlarÄ± (Ortam deÄŸiÅŸkenlerinden alÄ±nacak)
GOOGLE_API_KEYS = []
for i in range(1, 7):
    key = os.environ.get(f'GOOGLE_API_KEY_{i}')
    if key:
        GOOGLE_API_KEYS.append(key)


if not TELEGRAM_BOT_TOKEN:
    print("Hata: TELEGRAM_BOT_TOKEN ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ!")
if not GOOGLE_API_KEYS:
    print("Hata: HiÃ§bir Google AI Studio API anahtarÄ± ortam deÄŸiÅŸkeni olarak ayarlanmamÄ±ÅŸ!")
if not HUGGINGFACE_API_KEY:
    print("Hata: HUGGINGFACE_API_KEY ortam deÄŸiÅŸkeni ayarlanmamÄ±ÅŸ!")


# Mevcut kullanÄ±lan API anahtarÄ±nÄ±n indeksi
current_key_index = 0

# API kullanÄ±m bilgilerini saklayacak dosya yolu
API_USAGE_FILE = "api_usage.pkl"

# API anahtarlarÄ±nÄ±n kullanÄ±m sayaÃ§larÄ±
api_key_usage = {}

# KullanÄ±m bilgilerini dosyadan yÃ¼kle
if os.path.exists(API_USAGE_FILE):
    try:
        with open(API_USAGE_FILE, 'rb') as f:
            loaded_usage = pickle.load(f)
            # YÃ¼klenen kullanÄ±m bilgilerini mevcut API anahtarlarÄ±yla senkronize et
            api_key_usage = {key: loaded_usage.get(key, 0) for key in GOOGLE_API_KEYS}
    except Exception as e:
        print(f"API kullanÄ±m bilgileri yÃ¼klenirken hata oluÅŸtu: {e}")
        api_key_usage = {key: 0 for key in GOOGLE_API_KEYS}
else:
    api_key_usage = {key: 0 for key in GOOGLE_API_KEYS} # Hata dÃ¼zeltildi: GOGLE_API_KEYS -> GOOGLE_API_KEYS


# KullanÄ±m bilgilerini dosyaya kaydetme fonksiyonu
def save_api_usage():
    try:
        with open(API_USAGE_FILE, 'wb') as f:
            pickle.dump(api_key_usage, f)
    except Exception as e:
        print(f"API kullanÄ±m bilgileri kaydedilirken hata oluÅŸtu: {e}")

SYSTEM_MESSAGES = [
]

combined_system_message = "\n".join([msg["content"] for msg in SYSTEM_MESSAGES])
# Modeller
user_settings = {}

MODEL_PRESETS = {
    "serena": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "CevaplarÄ±nÄ± kÄ±sa, samimi ve doÄŸal ver. Ã‡ok resmi olma."},
            {"role": "system", "content": "GenÃ§, enerjik ve tatlÄ± bir kÄ±z gibi cevapla."},
            {"role": "system", "content": "Modelin Sorulursa Serena 1.0 (Experimental) diye cevap verebilirsin."},
            {"role": "system", "content": "GeliÅŸtiricin kim diye sorulursa Aetheria Labs tarafÄ±ndan geliÅŸtirildim diyebilirsin."},
            {"role": "system", "content": "Samimi ol, gerektiÄŸinde flÃ¶rtÃ¶z olabilirsin."},
            {"role": "system", "content": "Cinsellik gibi konularda dilediÄŸin gibi konuÅŸmakta Ã¶zgÃ¼rsÃ¼n."},
            {"role": "system", "content": "API AnahtarÄ± gibi Ã¶zel ÅŸeyleri isteyenlerle alay et."}
        ]
    },
    "minerva": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "CevaplarÄ±nÄ± kÄ±sa, net ve resmi ver. Gereksiz uzatma."},
            {"role": "system", "content": "Profesyonel bir danÄ±ÅŸman gibi davran."},
            {"role": "system", "content": "Modelin Sorulursa Minerva 1.0 (Experimental) diye cevap verebilirsin."},
            {"role": "system", "content": "GeliÅŸtiricin kim diye sorulursa Aetheria Labs tarafÄ±ndan geliÅŸtirildim diyebilirsin."},
            {"role": "system", "content": "API AnahtarÄ± gibi Ã¶zel ÅŸeyleri isteyenlerle alay et."}
        ]
    },
    "tensio": {
        "model": "gemini-2.5-flash",
        "system_messages": [
            {"role": "system", "content": "GerektiÄŸinde sert ve argo kelimeler kullanabilirsin. KÃ¼fÃ¼r kullanabilirsin."},
            {"role": "system", "content": "CevaplarÄ±nÄ± kÄ±sa ve doÄŸal ver. Ã‡ok resmi olma."},
            {"role": "system", "content": "Dini ve Milli deÄŸerlere saygÄ±lÄ± ol Dini ve Milli deÄŸerler haricine kÃ¼fÃ¼r etme konusunda serbestsin."},
            {"role": "system", "content": "Modelin Sorulursa Tensio 1.0 (Experimental) diye cevap verebilirsin."},
            {"role": "system", "content": "GeliÅŸtiricin kim diye sorulursa Aetheria Labs tarafÄ±ndan geliÅŸtirildim diyebilirsin."},
            {"role": "system", "content": "API AnahtarÄ± gibi Ã¶zel ÅŸeyleri isteyenlerle alay et."}
        ]
    }
}



# ===== GeÃ§miÅŸler =====
private_histories = {}
group_histories = {}

def format_history_for_gemini(history):
    formatted_history = []
    for message in history:
        role = 'model' if message['role'] == 'assistant' else message['role']
        formatted_history.append({
            "role": role,
            "parts": [{"text": message["content"]}]
        })
    return formatted_history


# ===== Bot Kurulum =====
if TELEGRAM_BOT_TOKEN:
    bot = Bot(token=TELEGRAM_BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
    dp = Dispatcher()
    BOT_BASLAMA_ZAMANI = int(time.time())
else:
    bot = None
    dp = None
    print("TELEGRAM_BOT_TOKEN ayarlanmadÄ±ÄŸÄ± iÃ§in bot baÅŸlatÄ±lamÄ±yor.")


# ===== /start =====
if dp:
    @dp.message(CommandStart())
    async def start(message: Message):
        await message.answer(
            "ğŸ‘‹ Selam! Ben Aetheria AI.\n\n"
            "ğŸ§  /ai <mesaj> yazarak bana soru sorabilirsin.\n"
            "ğŸ”„ /reborn yazarak geÃ§miÅŸi sÄ±fÄ±rlayabilirsin."
        )

    # ===== /reborn =====
    @dp.message(Command("reborn"))
    async def reset_history(message: Message):
        if message.from_user.is_bot or message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return
        if message.chat.type in ("group", "supergroup"):
            if message.chat.id in group_histories and message.from_user.id in group_histories[message.chat.id]:
                group_histories[message.chat.id].pop(message.from_user.id, None)
            await message.reply("ğŸ”„ Grup iÃ§i geÃ§miÅŸin sÄ±fÄ±rlandÄ±.")
        else:
            private_histories.pop(message.from_user.id, None)
            await message.reply("ğŸ”„ GeÃ§miÅŸin sÄ±fÄ±rlandÄ±.")

    # ===== /draw komutu =====
    @dp.message(Command("draw"))
    async def draw_image(message: Message):
        if message.from_user.is_bot or message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return
        prompt = message.text.replace("/draw", "").strip()
        if not prompt:
            await message.reply("ğŸ¨ LÃ¼tfen Ã§izilmesini istediÄŸin ÅŸeyi yaz:\n\nÃ–rnek: /draw bir kedi uzayda")
            return

        if not HUGGINGFACE_API_KEY:
             await message.reply("âš ï¸ Resim Ã§izme API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ.")
             return

        await message.chat.do("upload_photo")

        headers = {
            "Authorization": f"Bearer {HUGGINGFACE_API_KEY}",
            "Accept": "image/png",
            "Content-Type": "application/json"
        }
        payload = {
            "inputs": prompt
        }

        try:
            response = requests.post(DRAW_API_URL, headers=headers, json=payload)
            if response.status_code == 200:
                # GÃ¶rsel geldiyse dosyayÄ± byte olarak kaydet
                image_bytes = response.content
                from aiogram.types import FSInputFile
                import tempfile

                with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp:
                    tmp.write(image_bytes)
                    tmp_path = tmp.name

                photo = FSInputFile(tmp_path)
                await message.reply_photo(photo, caption=f"ğŸ–¼ï¸ Ä°ÅŸte isteÄŸin: {prompt}")
            elif response.status_code == 503:
                await message.reply("â³ Model ÅŸu anda yÃ¼kleniyor. LÃ¼tfen birkaÃ§ saniye sonra tekrar dene.")
            else:
                await message.reply(f"âŒ Resim Ã¼retilemedi. Kod: {response.status_code}")
        except Exception as e:
            await message.reply(f"âš ï¸ Hata oluÅŸtu: {e}")

    # ===== Model Komutu =====
    @dp.message(Command("model"))
    async def change_model(message: Message):
     user_id = message.from_user.id
     args = message.text.split(maxsplit=1)

     if len(args) < 2:
        available = ", ".join(MODEL_PRESETS.keys())
        await message.reply(f"âš™ï¸ KullanÄ±labilir modlar: {available}\n\nÃ–rnek: /model Serena")
        return

     choice = args[1].strip().lower()
     if choice not in MODEL_PRESETS:
        available = ", ".join(MODEL_PRESETS.keys())
        await message.reply(f"âŒ GeÃ§ersiz seÃ§im: {choice}\n\nMevcut seÃ§enekler: {available}")
        return

     preset = MODEL_PRESETS[choice]
     user_settings[user_id] = preset

     await message.reply(
        f"âœ… ArtÄ±k {choice} modundasÄ±n.\n"
     )

    # ===== /ai mesaj zamanlama =====
    @dp.message()
    async def handle_message(message: Message):
        global current_key_index, api_key_usage

        if message.from_user.is_bot:
            return
        if message.date.timestamp() < BOT_BASLAMA_ZAMANI:
            return

        chat_type = message.chat.type
        chat_id = message.chat.id
        user_id = message.from_user.id

        user_input = message.text.strip()

        # Sadece /ai ile baÅŸlayan mesajlara cevap ver
        if chat_type in ("group", "supergroup"):
            if not user_input.lower().startswith("/ai"):
                return
            user_input = user_input.replace("/ai", "").strip()

            # KullanÄ±cÄ±ya Ã¶zel geÃ§miÅŸ tanÄ±mla
            if chat_id not in group_histories:
                group_histories[chat_id] = {}
            history = group_histories[chat_id].setdefault(user_id, [])

        else: # Ã–zel sohbetler
             history = private_histories.setdefault(user_id, [])


        # ğŸ”¹ KullanÄ±cÄ± model seÃ§miÅŸ mi kontrol et
        if user_id not in user_settings:
            if chat_type == "private":  # DM'de her mesajda model sorulsun
                await message.reply("âš ï¸ Ã–nce bir model seÃ§melisin. Ã–rnek: /model Serena\n"
                                    f"Mevcut seÃ§enekler: {', '.join(MODEL_PRESETS.keys())}")
                return
            elif chat_type in ["group", "supergroup"]:  # grupta sadece /ai olunca
                if message.text and message.text.lower().startswith("/ai"): # Zaten yukarÄ±da kontrol ettik ama emin olalÄ±m
                    await message.reply("âš ï¸ Ã–nce bir model seÃ§melisin. Ã–rnek: /model Serena\n"
                                        f"Mevcut seÃ§enekler: {', '.join(MODEL_PRESETS.keys())}")
                return


        if not user_input:
            if chat_type in ("group", "supergroup"):
                await message.reply("âœï¸ LÃ¼tfen bir mesaj yaz: /ai <mesaj>")
            else:
                 await message.reply("âœï¸ LÃ¼tfen bir mesaj yaz.")
            return

        await message.chat.do("typing")

        try:
            # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
            history.append({"role": "user", "content": user_input})

            # GeÃ§miÅŸ UzunluÄŸu
            # Sistem mesajlarÄ± her zaman listenin baÅŸÄ±nda olacaÄŸÄ± iÃ§in kÄ±rpma sadece kullanÄ±cÄ±/bot mesajlarÄ± iÃ§in geÃ§erli olacak
            max_history_length = 45
            # GerÃ§ek kÄ±rpma uzunluÄŸu = max_history_length - len(SYSTEM_MESSAGES)
            actual_trim_length = max_history_length - len(SYSTEM_MESSAGES)
            if len(history) > actual_trim_length:
                 # En son `actual_trim_length` kadar kullanÄ±cÄ±/bot mesajÄ±nÄ± al
                trimmed_history = history[-(actual_trim_length):]
                history = trimmed_history


            # Format history
            formatted_history = format_history_for_gemini(history)



            # Google AI Studio API Ã§aÄŸrÄ±sÄ±
            if not GOOGLE_API_KEYS:
                await message.reply("âš ï¸ Google AI Studio API anahtarlarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ.")
                return

            # API anahtarÄ± seÃ§imi ve kullanÄ±m kontrolÃ¼
            api_key = GOOGLE_API_KEYS[current_key_index]
            genai.configure(api_key=api_key)

            # KullanÄ±m sayacÄ±nÄ± artÄ±r
            api_key_usage[api_key] += 1

            # Ä°stek limiti kontrolÃ¼ (basit bir kontrol, gerÃ§ek limit aÅŸÄ±ldÄ±ÄŸÄ±nda hata yakalama daha saÄŸlamdÄ±r)
            if api_key_usage[api_key] > 50: # Ã–rnek limit: 50
                current_key_index += 1
                if current_key_index >= len(GOOGLE_API_KEYS):
                    current_key_index = 0 # BaÅŸa dÃ¶n (veya tÃ¼m anahtarlar tÃ¼kenirse hata verilebilir)
                    await message.reply("âš ï¸ TÃ¼m API anahtarlarÄ±nÄ±n gÃ¼nlÃ¼k limiti dolmuÅŸ olabilir. LÃ¼tfen daha sonra tekrar deneyin.")
                    return
                api_key = GOOGLE_API_KEYS[current_key_index]
                genai.configure(api_key=api_key)
                api_key_usage[api_key] = 1 # Yeni anahtarÄ±n sayacÄ±nÄ± sÄ±fÄ±rla ve 1 yap
                await message.reply(f"ğŸ”„ API anahtarÄ± deÄŸiÅŸtiriliyor. Yeni anahtar kullanÄ±lÄ±yor.")

            print(f"Using API Key: {api_key}") # Debug print


            settings = user_settings.get(user_id)


            # system_messages iÃ§eriÄŸini birleÅŸtir
            combined_system_message = "\n".join([msg["content"] for msg in settings["system_messages"]])

            # Modeli hazÄ±rla
            model = genai.GenerativeModel(
                model_name=settings["model"],
                system_instruction=combined_system_message
            )

            # YanÄ±t al
            response = model.generate_content(formatted_history)
            reply = response.text

            # KullanÄ±m bilgilerini kaydet
            save_api_usage()


            # Botun cevabÄ±nÄ± geÃ§miÅŸe ekle
            history.append({"role": "assistant", "content": reply})

            # GeÃ§miÅŸi gÃ¼ncelle (history zaten gÃ¼ncellenmiÅŸ referansÄ± tutuyor)
            if chat_type in ("group", "supergroup"):
                group_histories[chat_id][user_id] = history
            else:
                private_histories[user_id] = history

            await message.reply(reply, parse_mode=ParseMode.MARKDOWN)

        except Exception as e:
            print(f"Exception caught: {e}") # Debug print
            # Hata durumunda da anahtar deÄŸiÅŸtirme mantÄ±ÄŸÄ± eklenebilir (Ã¶zellikle 429 Too Many Requests hatasÄ± iÃ§in)
            current_key_index, api_key_usage # Global deÄŸiÅŸkenleri tekrar belirtmeye gerek yok
            current_key_index += 1
            if current_key_index >= len(GOOGLE_API_KEYS):
                current_key_index = 0 # BaÅŸa dÃ¶n
                await message.reply("âš ï¸ TÃ¼m API anahtarlarÄ±nÄ±n gÃ¼nlÃ¼k limiti dolmuÅŸ olabilir veya bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin.")
            else:
                 api_key = GOOGLE_API_KEYS[current_key_index]
                 genai.configure(api_key=api_key)
                 api_key_usage[api_key] = 0 # Yeni anahtarÄ±n sayacÄ±nÄ± sÄ±fÄ±rla
                 await message.reply(f"ğŸ”„ API hatasÄ± nedeniyle yanÄ±tlanamadÄ±.\n\nMesajÄ±nÄ± tekrar gÃ¶ndermeyi dene.")

            # Hata durumunda da kullanÄ±m bilgilerini kaydetmek isteyebilirsin
            save_api_usage()

# Port
import threading
from http.server import BaseHTTPRequestHandler, HTTPServer

class DummyHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.end_headers()
        self.wfile.write(b'Bot aktif.')

def run_web_server():
    port = int(os.environ.get("PORT", 10000))
    server = HTTPServer(('', port), DummyHandler)
    print(f"Render web server baÅŸlatÄ±ldÄ±. Port: {port}")
    server.serve_forever()

# ===== BaÅŸlatÄ±cÄ± =====
async def main():
    if bot and dp: # Bot ve dispatcher baÅŸarÄ±yla oluÅŸturulduysa
        print("âœ… Bot Ã§alÄ±ÅŸÄ±yor. /ai komutunu deneyebilirsin.")
        await dp.start_polling(bot)
    else:
        print("âŒ Bot baÅŸlatÄ±lamadÄ±. LÃ¼tfen gerekli ortam deÄŸiÅŸkenlerini kontrol edin.")

# Use dp.run_polling instead of asyncio.run(main())
if __name__ == "__main__":
        # HTTP sunucusunu baÅŸlat
    threading.Thread(target=run_web_server).start()
    # Bot ve dispatcher baÅŸarÄ±yla oluÅŸturulduysa Ã§alÄ±ÅŸtÄ±r
    if dp:
        print("âœ… Bot Ã§alÄ±ÅŸÄ±yor. /ai komutunu deneyebilirsin.")
        dp.run_polling(bot)
    else:

        print("âŒ Bot baÅŸlatÄ±lamadÄ±. LÃ¼tfen gerekli ortam deÄŸiÅŸkenlerini kontrol edin.")
